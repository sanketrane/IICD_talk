class: middle

### 1. Ontogeny dataset

Total counts and proportions of $\small \text{Ki}67^{high}$ cells from d5 to d300 in mice.


### 2. Timestamp dataset

Data from a mouse system that allows us to track cohorts of naive T cells as they leave the thymus.

</br>

???

### Our goal is to use these data together to test grand-unified models of Naive T cell homeostasis from birth to death.

---

### Dynamics of Naive T cell pool size and Ki67 expression
<hr>


```{r echo=FALSE, fig.retina=3, out.width='80%'}

knitr::include_graphics("figures/counts_data.jpeg")
```

--

```{r echo=FALSE, fig.retina=3, out.width='80%'}

knitr::include_graphics("figures/ki_data.jpeg")
```

???

### .center[Measuring cell division in T lymphocytes]
<hr>

- $\small \text{Ki}67$ â€” a nuclear protein expressed during cell-division.

</br>

---
class: center
### .left[Neutral and Competition Models]
<hr>

```{r echo=FALSE, fig.retina=3, out.width='420'}

knitr::include_graphics("figures/neutral_diag.png")
```

.left[
$$
\small
\begin{aligned}
&N(t) = N^+(t) + N^-(t); \quad
&\kappa(t) = \frac{N^+(t)}{N(t)}
\end{aligned}
$$
]

--

</br>

.shadedbox[
$$
\begin{aligned}
&\dot N^+ = \alpha \, \theta^+(t) + \rho(N) \, (2\,N^- + N^+) - (\beta + \delta(N)) \, N^+ \\
&\dot N^- = \alpha \, \theta^-(t) + \beta N^+ + \delta(N)) \, N^-
\end{aligned}
$$
]


???


---
### Model vaildation and comparison
<hr>

- Each model was fitted simultaneously to the timecourses of $\small log(\text{counts})$  and $\small logit(\text{Ki}67^\text{high}\text{ proportions})$ cells.

$$
\text{Joint Likelihood} \Rightarrow \quad  p(y | \hat \theta) = \prod_{i=1}^n \, \text{Normal}(y_i - \text{model}(\theta)_i^\text{pred}, \, \sigma) 
$$

???
Each model was fitted simultaneously to the timecourses of $\small log(\text{counts})$   proportions of $\small logit(\text{Ki}67^{high})$ cells.

We form a joint likelihood which is the probability density of data across the parameter distribution $\theta$ by assuming that the errors are normally distributed. 

--

$$
\text{Bayesian approach}\Rightarrow \quad 
p(\hat \theta | y) = \frac{p(y | \hat \theta) \times p(\theta_\text{prior})} {p(y)}
$$

<hr>
???
- This probability density is then used to update our prior beliefs in model parameters using the bayesian approach.


We judge the models under consideration based on **parsimony** and their ability to predict **New observations** which is also called as out of sample prediction error.

--

</br>

.shadedbox2[
Occam's razor:
Models are selected based on **parsimony** and their ability to predict **New observations** &mdash; (out-of-sample prediction error).
]


---

<hr>
### Mesuring out-of-sample prediction error using Leave-One-Out cross validation.

```{r echo=FALSE, fig.retina=3, out.width="40%"}

knitr::include_graphics("figures/looic.png")
```


$$
\text{Leave-One-Out information criterion:} \,\,
\small \text{LooIC} = -2 \,\, \sum_{i=1}^n \, Z_i
$$

<hr>

???
We measure this  out of sample prediction error using Leave-One-Out cross validation, in which a single observation is treated as test dataset and rest of the observations are trated as training data. The process is repeated for all 'n' observations and the prediction error for each left-out test set is aggregated to calculate Leave-One-Out information criterion (LOOIC).


--

- Relative support: Akaike weight
.shadedbox[
$$
\omega_i = \frac{exp(-\frac{1}{2} \, [\text{LooIC}]_i)}{\sum_m^M  \, exp(-\frac{1}{2} \, [\text{LooIC}]_m)}
$$
]

???
We then used the estimated LOO-IC values to assess the relative support for models using the analog of the Akaike weight which gives us the probability that a given model will explain new data better than other models considered in this analysis.
\

